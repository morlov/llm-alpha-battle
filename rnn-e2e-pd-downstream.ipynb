{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af790b9-f4cc-40e0-a28a-7f11fc403b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13d934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc0f45-6d4c-4026-ab33-bb58d1c5a5c7",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a491a9e2-62f6-41f8-9010-0cec157dbded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "\n",
    "conf = OmegaConf.load('config/coles.yaml')\n",
    "model = hydra.utils.instantiate(conf.pl_module)\n",
    "model.load_state_dict(torch.load(\"models/coles.p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a2c03-a0e6-4241-8d56-abb4eb5b1d97",
   "metadata": {},
   "source": [
    "# Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f01ebcc-e64c-445c-a267-7ec430f9c73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morlov/.local/share/virtualenvs/pytorch-lifestream-1iBTwtzi/lib/python3.8/site-packages/ptls/data_load/datasets/parquet_dataset.py:106: UserWarning: `post_processing` parameter is deprecated, use `i_filters`\n",
      "  warnings.warn('`post_processing` parameter is deprecated, use `i_filters`')\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\n",
    "from ptls.data_load.iterable_processing.feature_filter import FeatureFilter\n",
    "from ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.frames.supervised import SeqToTargetDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from ptls.data_load import IterableChain\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.data_load.datasets.parquet_dataset import ParquetDataset, ParquetFiles\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.frames import PtlsDataModule\n",
    "\n",
    "train_data = glob('data/train_transactions_clipped.parquet')\n",
    "valid_data = glob('data/valid_transactions_clipped.parquet')\n",
    "\n",
    "feature_cols = list(conf.pl_module.seq_encoder.trx_encoder.embeddings.keys()) + \\\n",
    "               list(conf.pl_module.seq_encoder.trx_encoder.numeric_values.keys())\n",
    "\n",
    "dataset_conf = {\n",
    "    'min_seq_len':25,\n",
    "    }\n",
    "\n",
    "\n",
    "process = IterableChain(\n",
    "            SeqLenFilter(min_seq_len=dataset_conf['min_seq_len']),\n",
    "            FeatureFilter(keep_feature_names=feature_cols + ['flag']),\n",
    "            ToTorch()\n",
    "            )\n",
    "    \n",
    "def get_dataset(data):\n",
    "    ds = MemoryMapDataset(ParquetDataset(data, post_processing=process))\n",
    "    return SeqToTargetDataset(ds, target_col_name='flag')\n",
    "\n",
    "train_ds = get_dataset(train_data)\n",
    "valid_ds = get_dataset(valid_data)\n",
    "\n",
    "dm = PtlsDataModule(\n",
    "    train_data=train_ds,\n",
    "    valid_data=valid_ds,\n",
    "    train_num_workers=4,\n",
    "    train_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371c0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "import torchmetrics\n",
    "from ptls.frames.supervised import SequenceToTarget\n",
    "from ptls.nn import Head\n",
    "\n",
    "model_e2e = SequenceToTarget(\n",
    "    seq_encoder=model.seq_encoder,\n",
    "    head=Head(\n",
    "        input_size=model.seq_encoder.embedding_size,\n",
    "        use_batch_norm=True,\n",
    "        objective='classification',\n",
    "        num_classes=2,\n",
    "    ),\n",
    "    loss=torch.nn.NLLLoss(),\n",
    "    metric_list=torchmetrics.Accuracy(compute_on_step=False),\n",
    "    pretrained_lr=0.00001,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001, weight_decay=1e-5),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=10, gamma=0.9),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0448fa-1405-4418-8fb9-e4ff0e53e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus: 1\n",
      "auto_select_gpus: false\n",
      "max_epochs: 5\n",
      "deterministic: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "trainer_params = conf.trainer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer_params = conf.trainer\n",
    "trainer_params['max_epochs'] = 5\n",
    "callbacks = [ModelCheckpoint(every_n_epochs=5, save_top_k=-1), LearningRateMonitor(logging_interval='step')]\n",
    "logger = TensorBoardLogger(save_dir='lightning_logs', name=conf.get('logger_name'))\n",
    "\n",
    "print(OmegaConf.to_yaml(trainer_params))\n",
    "\n",
    "trainer = pl.Trainer(**trainer_params, callbacks=callbacks, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af5db53-47b3-49ff-bf8a-49a3abc958ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 284 K \n",
      "1 | head          | Head          | 1.0 K \n",
      "2 | loss          | NLLLoss       | 0     \n",
      "3 | train_metrics | ModuleDict    | 0     \n",
      "4 | valid_metrics | ModuleDict    | 0     \n",
      "5 | test_metrics  | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "285 K     Trainable params\n",
      "0         Non-trainable params\n",
      "285 K     Total params\n",
      "1.142     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2eb5a0e8f34d6895bc0e7157353b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.1038), 'seq_len': tensor(89.4000), 'y': tensor(0.0182), 'val_loss': tensor(0.1063), 'val_Accuracy': tensor(0.9739), 'train_Accuracy': tensor(0.9714)}\n",
      "CPU times: user 11min 14s, sys: 54.7 s, total: 12min 9s\n",
      "Wall time: 12min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'logger.version = {trainer.logger.version}')\n",
    "trainer.fit(model_e2e, dm)\n",
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c27702ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_e2e.state_dict(), \"models/rnn-e2e-pd.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba14724-6df5-4b97-b7d7-aae8c7c50c11",
   "metadata": {},
   "source": [
    "# Infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f9f7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_e2e.load_state_dict(torch.load(\"models/rnn-e2e-pd.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df76e38-ec88-461c-aa41-572f134eb531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "import tqdm\n",
    "\n",
    "def inference(model, dl, device='cuda:0'):\n",
    "    \n",
    "    model.to(device)\n",
    "    X = []\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            features = batch[0]\n",
    "            targets = [batch[1].to(device).unsqueeze(dim=1)]\n",
    "            x = model(features.to(device))\n",
    "            flag = x[:, 1].unsqueeze(dim=1)\n",
    "            predicted = [flag]\n",
    "            X += [torch.cat(predicted + targets, dim=1)]\n",
    "    return X\n",
    "\n",
    "\n",
    "valid_dl = torch.utils.data.DataLoader(dataset=valid_ds, \n",
    "                                       collate_fn=valid_ds.collate_fn,\n",
    "                                       num_workers=8,\n",
    "                                       batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17e69c3a-d4c8-4288-8902-e6b90c9606df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 406/406 [00:08<00:00, 47.58it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = torch.vstack(inference(model_e2e, valid_dl)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6db0f6de-3ecd-4853-8993-223afee0af4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_flag</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.250740</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.428023</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536288</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.059521</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.243661</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_flag  flag\n",
       "0       -2.250740   0.0\n",
       "1       -3.428023   0.0\n",
       "2       -1.536288   1.0\n",
       "3       -5.059521   0.0\n",
       "4       -5.243661   0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_valid = pd.DataFrame(preds, columns = ['predicted_flag', 'flag'])\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f9b3d0-092b-4f7e-9108-ca7db9aa700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc AUC score: {0.7761719920016419}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"Roc AUC score:\", {roc_auc_score(df_valid['flag'],  df_valid['predicted_flag'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c976e0-0499-4d4d-b584-38d7f45c218f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptls",
   "language": "python",
   "name": "ptls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
