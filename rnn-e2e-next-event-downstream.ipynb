{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af790b9-f4cc-40e0-a28a-7f11fc403b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13d934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc0f45-6d4c-4026-ab33-bb58d1c5a5c7",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a491a9e2-62f6-41f8-9010-0cec157dbded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "\n",
    "conf = OmegaConf.load('config/coles.yaml')\n",
    "model = hydra.utils.instantiate(conf.pl_module)\n",
    "model.load_state_dict(torch.load(\"models/coles.p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a2c03-a0e6-4241-8d56-abb4eb5b1d97",
   "metadata": {},
   "source": [
    "# Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f01ebcc-e64c-445c-a267-7ec430f9c73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morlov/.local/share/virtualenvs/pytorch-lifestream-1iBTwtzi/lib/python3.8/site-packages/ptls/data_load/datasets/parquet_dataset.py:106: UserWarning: `post_processing` parameter is deprecated, use `i_filters`\n",
      "  warnings.warn('`post_processing` parameter is deprecated, use `i_filters`')\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\n",
    "from ptls.data_load.iterable_processing.target_move import TargetMove\n",
    "from ptls.data_load.iterable_processing.target_empty_filter import TargetEmptyFilter\n",
    "from ptls.data_load import padded_collate, padded_collate_wo_target\n",
    "from ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from ptls.data_load import IterableChain\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.data_load.datasets.parquet_dataset import ParquetDataset, ParquetFiles\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "\n",
    "\n",
    "from ptls.frames import PtlsDataModule\n",
    "\n",
    "train_data = glob('data/train_transactions_clipped.parquet')\n",
    "valid_data = glob('data/valid_transactions_clipped.parquet')\n",
    "\n",
    "feature_cols = list(conf.pl_module.seq_encoder.trx_encoder.embeddings.keys()) + \\\n",
    "               list(conf.pl_module.seq_encoder.trx_encoder.numeric_values.keys())\n",
    "\n",
    "target_cols = ['mcc', 'amnt', 'hour_diff']\n",
    "\n",
    "dataset_conf = {\n",
    "    'min_seq_len':25,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "class SeqToTargetMultiheadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 feature_cols,\n",
    "                 target_cols,\n",
    "                 target_dtype=None,\n",
    "                 *args, **kwargs,\n",
    "                 ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.data = data\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_cols = target_cols\n",
    "        \n",
    "        if type(target_dtype) is str:\n",
    "            self.target_dtype = getattr(torch, target_dtype)\n",
    "        else:\n",
    "            self.target_dtype = target_dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        feature_arrays = self.data[item]\n",
    "        return feature_arrays\n",
    "\n",
    "    def __iter__(self):\n",
    "        for feature_arrays in self.data:\n",
    "            yield feature_arrays\n",
    "\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \n",
    "        targets = []\n",
    "        values = []\n",
    "        \n",
    "        for target_col in target_cols:\n",
    "            targets.append(torch.tensor([rec[target_col][-1] for rec in batch]).to(self.target_dtype[target_col]))\n",
    "        \n",
    "        for rec in batch:\n",
    "            values.append({k: v[:-1] for k, v in rec.items() if k in feature_cols})\n",
    "    \n",
    "        return padded_collate_wo_target(values), targets\n",
    "\n",
    "process = IterableChain(\n",
    "            SeqLenFilter(min_seq_len=dataset_conf['min_seq_len']),\n",
    "            ToTorch()\n",
    "            )\n",
    "    \n",
    "def get_dataset(data):\n",
    "    ds = MemoryMapDataset(ParquetDataset(data, post_processing=process))\n",
    "    return SeqToTargetMultiheadDataset(ds, feature_cols, target_cols, target_dtype = {'mcc': torch.long, 'amnt': torch.float, 'hour_diff': torch.float})\n",
    "\n",
    "train_ds = get_dataset(train_data)\n",
    "valid_ds = get_dataset(valid_data)\n",
    "\n",
    "dm = PtlsDataModule(\n",
    "    train_data=train_ds,\n",
    "    valid_data=valid_ds,\n",
    "    train_num_workers=4,\n",
    "    train_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371c0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from copy import deepcopy\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchmetrics\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from ptls.data_load.padded_batch import PaddedBatch\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class SequenceToTargetMultihead(pl.LightningModule):\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 seq_encoder: torch.nn.Module,\n",
    "                 heads: List[torch.nn.Module],\n",
    "                 losses: List[torch.nn.Module],\n",
    "                 metric_list: torchmetrics.Metric=None,\n",
    "                 optimizer_partial=None,\n",
    "                 lr_scheduler_partial=None,\n",
    "                 pretrained_lr=None,\n",
    "                 train_update_n_steps=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\n",
    "            'seq_encoder', 'heads', 'losses', 'metric_list', 'optimizer_partial', 'lr_scheduler_partial'])\n",
    "\n",
    "        self.seq_encoder = seq_encoder\n",
    "        self.heads = heads\n",
    "        self.losses = losses\n",
    "        self.n_heads = len(heads)\n",
    "\n",
    "        self.optimizer_partial = optimizer_partial\n",
    "        self.lr_scheduler_partial = lr_scheduler_partial\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq_encoder(x)\n",
    "        xs = [head(x) for head in self.heads]\n",
    "        return xs\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        y_hs = self(x)\n",
    "        loss = sum([loss(y_hs[i], y[i]) for i, loss in enumerate(self.losses)])\n",
    "        self.log('loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        y_hs = self(x)\n",
    "        loss = sum([loss(y_hs[i], y[i]) for i, loss in enumerate(self.losses)])\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.pretrained_lr is not None:\n",
    "            if self.hparams.pretrained_lr == 'freeze':\n",
    "                for p in self.seq_encoder.parameters():\n",
    "                    p.requires_grad = False\n",
    "                parameters = self.parameters()\n",
    "            else:\n",
    "                parameters = [\n",
    "                    {'params': self.seq_encoder.parameters(), 'lr': self.hparams.pretrained_lr},\n",
    "                ] + [{'params': head.parameters()} for head in self.heads]\n",
    "        else:\n",
    "            parameters = self.parameters()\n",
    "\n",
    "        optimizer = self.optimizer_partial(parameters)\n",
    "        scheduler = self.lr_scheduler_partial(optimizer)\n",
    "        return [optimizer], [scheduler]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df848227-4a6e-4096-9125-986b603693f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "import torchmetrics\n",
    "from ptls.nn import Head\n",
    "\n",
    "\n",
    "head_mcc = Head(input_size=model.seq_encoder.embedding_size, \n",
    "                use_batch_norm=True,\n",
    "                hidden_layers_sizes=[128],\n",
    "                objective='classification',\n",
    "                num_classes=109).to('cuda:0')\n",
    "\n",
    "head_amnt = Head(input_size=model.seq_encoder.embedding_size, \n",
    "                 use_batch_norm=True,\n",
    "                 hidden_layers_sizes=[128],\n",
    "                 objective='softplus').to('cuda:0')\n",
    "\n",
    "head_hour_diff = Head(input_size=model.seq_encoder.embedding_size, \n",
    "                      use_batch_norm=True,\n",
    "                      hidden_layers_sizes=[128],\n",
    "                      objective='softplus').to('cuda:0')\n",
    "\n",
    "model_multihead = SequenceToTargetMultihead(\n",
    "    seq_encoder=model.seq_encoder,\n",
    "    heads=[head_mcc, head_amnt, head_hour_diff],\n",
    "    losses=[torch.nn.NLLLoss(), torch.nn.L1Loss(), torch.nn.L1Loss()],\n",
    "    metric_list=torchmetrics.Accuracy(compute_on_step=False),\n",
    "    pretrained_lr=False, # 0.00001,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001), # , weight_decay=1e-5\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=1, gamma=0.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d0448fa-1405-4418-8fb9-e4ff0e53e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus: 1\n",
      "auto_select_gpus: false\n",
      "max_epochs: 30\n",
      "deterministic: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "trainer_params = conf.trainer\n",
    "print(OmegaConf.to_yaml(trainer_params))\n",
    "\n",
    "\n",
    "\n",
    "trainer_params = conf.trainer\n",
    "trainer_params['max_epochs']  = 15\n",
    "callbacks = [ModelCheckpoint(every_n_epochs=5, save_top_k=-1), LearningRateMonitor(logging_interval='step')]\n",
    "logger = TensorBoardLogger(save_dir='lightning_logs', name=conf.get('logger_name'))\n",
    "trainer = pl.Trainer(**trainer_params, callbacks=callbacks, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af5db53-47b3-49ff-bf8a-49a3abc958ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type          | Params\n",
      "----------------------------------------------\n",
      "0 | seq_encoder | RnnSeqEncoder | 3.5 M \n",
      "----------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "13.933    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39827d8c1a284ad9ab2d9a3ca4b8755b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(111.0199), 'val_loss': tensor(114.0924)}\n",
      "CPU times: user 44min 32s, sys: 2min 20s, total: 46min 53s\n",
      "Wall time: 48min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'logger.version = {trainer.logger.version}')\n",
    "trainer.fit(model_multihead, dm)\n",
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27702ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_multihead.state_dict(), \"models/rnn-e2e-nep.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba14724-6df5-4b97-b7d7-aae8c7c50c11",
   "metadata": {},
   "source": [
    "# Infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f9f7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multihead.load_state_dict(torch.load(\"models/rnn-e2e-nep.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2df76e38-ec88-461c-aa41-572f134eb531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "import tqdm\n",
    "\n",
    "def inference(model, dl, device='cuda:0'):\n",
    "    \n",
    "    model.to(device)\n",
    "    X = []\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            features = batch[0]\n",
    "            targets = [t.unsqueeze(dim=1).to(device) for t in batch[1]]\n",
    "            x = model(features.to(device))\n",
    "            mcc = torch.argmax(x[0], dim=1, keepdim=True)\n",
    "            amnt = x[1].unsqueeze(dim=1)\n",
    "            hour_diff = x[2].unsqueeze(dim=1)\n",
    "            predicted = [mcc, amnt, hour_diff]\n",
    "            X += [torch.cat(predicted + targets, dim=1)]\n",
    "    return X\n",
    "\n",
    "\n",
    "valid_dl = torch.utils.data.DataLoader(dataset=valid_ds, \n",
    "                                       collate_fn=valid_ds.collate_fn,\n",
    "                                       num_workers=8,\n",
    "                                       batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e69c3a-d4c8-4288-8902-e6b90c9606df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 203/203 [00:06<00:00, 29.21it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = torch.vstack(inference(model_multihead, valid_dl)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6db0f6de-3ecd-4853-8993-223afee0af4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_mcc</th>\n",
       "      <th>predicted_amnt</th>\n",
       "      <th>predicted_hour_diff</th>\n",
       "      <th>mcc</th>\n",
       "      <th>amnt</th>\n",
       "      <th>hour_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.316761</td>\n",
       "      <td>15.209979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230493</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.314062</td>\n",
       "      <td>27.670671</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.208383</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.296456</td>\n",
       "      <td>4.204549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.249951</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.428839</td>\n",
       "      <td>22.073618</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.535713</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.321625</td>\n",
       "      <td>2.882242</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.410411</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_mcc  predicted_amnt  predicted_hour_diff   mcc      amnt  \\\n",
       "0            2.0        0.316761            15.209979   1.0  0.230493   \n",
       "1            2.0        0.314062            27.670671  14.0  0.208383   \n",
       "2            1.0        0.296456             4.204549   1.0  0.249951   \n",
       "3            2.0        0.428839            22.073618   2.0  0.535713   \n",
       "4            2.0        0.321625             2.882242  35.0  0.410411   \n",
       "\n",
       "   hour_diff  \n",
       "0        0.0  \n",
       "1       41.0  \n",
       "2        6.0  \n",
       "3       20.0  \n",
       "4       48.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_valid = pd.DataFrame(preds, columns = ['predicted_mcc', 'predicted_amnt', 'predicted_hour_diff', 'mcc', 'amnt', 'hour_diff'])\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1256856-3585-4b1d-ab90-68d7f2e74847",
   "metadata": {},
   "source": [
    "## MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c79f183d-f27b-4820-b15c-03b29be96436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: {0.45001733502831387}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", {accuracy_score(df_valid['mcc'],  df_valid['predicted_mcc'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f90007-39ca-413f-bb25-4fb6c4567417",
   "metadata": {},
   "source": [
    "# amnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e3029d3-18d5-4836-8459-9ad5fa667c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mae amnt: {0.080119364}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"Mae amnt:\", {mean_absolute_error(df_valid['amnt'],  df_valid['predicted_amnt'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8bfd43-9ddd-402d-a069-fa22e42ead36",
   "metadata": {},
   "source": [
    "# hour_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37c4697a-1ad9-4b11-904a-5d2cae5c0945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: {111.75027}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"Accuracy:\", {mean_absolute_error(df_valid['hour_diff'],  df_valid['predicted_hour_diff'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9b3d0-092b-4f7e-9108-ca7db9aa700a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptls",
   "language": "python",
   "name": "ptls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
